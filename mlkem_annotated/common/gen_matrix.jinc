require "mlkem_keccak_avx2.jinc"

// BUF_size per entry: 21(rate) + 21(rate) + 25(keccak_state) + 1(pad)
param int BUF_size = 536; // 168*2+200      (was in u64s: 3*21 + 4 + 1; //544 bytes;


inline fn __gen_matrix_buf_rejection_filter48
( reg mut ptr u16[MLKEM_N] pol
, reg u64 counter
, reg const ptr u8[BUF_size] buf
, reg u64 buf_offset // bytes

, reg u256 load_shuffle
, reg u256 mask
, reg u256 bounds
, reg ptr u8[2048] sst
, reg u256 ones
, #msf reg u64 ms
) -> reg ptr u16[MLKEM_N], reg u64
requires {is_arr_init(buf,0,BUF_size) && is_arr_init(sst,0,2048) && 
          0<= (int) counter && (int) counter + 32 <= MLKEM_N &&
          0 <= (int) buf_offset && (int) buf_offset + 24 + 32 <= BUF_size}
ensures { \all (k \in 0:((2*MLKEM_N))) (is_arr_init(result.0,k,1) == (is_arr_init(pol,k,1) || ((int) counter * 2 <= k && k< 2* (int) result.1))) }
ensures {(int) counter <=(int) result.1 && (int) result.1 <= MLKEM_N}
{
  reg u256 f0 f1 g0 g1;
  reg u256 shuffle_0 shuffle_1 shuffle_t;
  reg u128 shuffle_0_1 shuffle_1_1;
  reg u64 good t0_0 t0_1 t1_0 t1_1;

  // loads 24 bytes (while touching 32 bytes of memory) into f0 and another
  // 24 bytes into f1 while doing some rearrangements:
  // - consider that the memory contains the following 32 bytes (in u64s)
  // - 0x01aaaaaaaaaaaa08, 0x01bbbbbbbbbbbb08, 0x01cccccccccccc08, 0x01dddddddddddd08
  // - the command given to vpermq is 0x94, or (8u1)[1,0,0,1, 0,1,0,0], or (4u2)[2,1,1,0]
  // - so the last 8 bytes will be discarded:
  //   - 0x01aaaaaaaaaaaa08, 0x01bbbbbbbbbbbb08, 0x01bbbbbbbbbbbb08, 0x01cccccccccccc08

  f0 = #VPERMQ(buf.[u256 (int) buf_offset + 0 ], (4u2)[2,1,1,0]);
  f1 = #VPERMQ(buf.[u256 (int) buf_offset + 24], (4u2)[2,1,1,0]);

  // next, the data is shuffled at byte level. For a given state (in u64s):
  // - 0xa8a7a6a5a4a3a2a1, 0xb8b7b6b5b4b3b2b1, 0xc8c7c6c5c4c3c2c1, 0xd8d7d6d5d4d3d2d1
  // f's get rearranged into:
  // - 0xa6a5a5a4a3a2a2a1, 0xb4b3b3b2b1a8a8a7, 0xd2d1d1c8c7c6c6c5, 0xd8d7d7d6d5d4d4d3

  f0 = #VPSHUFB_256(f0, load_shuffle);
  f1 = #VPSHUFB_256(f1, load_shuffle);

  // next, a shift right by 4 (u16) is performed, for a given state:
  // (consider that c's hold the same values as b's ++ some underscores to help the reading)
  //
  // - 0xa6a5_a5a4_a3a2_a2a1, 0xb4b3_b3b2_b1a8_a8a7, 0xd2d1_d1c8_c7c6_c6c5, 0xd8d7_d7d6_d5d4_d4d3
  // to:
  // - 0x0a6a_0a5a_0a3a_0a2a, 0x0b4b_0b3b_0b1a_0a8a, 0x0d2d_0d1c_0c7c_0c6c, 0x0d8d_0d7d_0d5d_0d4d

  g0 = #VPSRL_16u16(f0, 4);
  g1 = #VPSRL_16u16(f1, 4);

  // next, blend.
  // from:
  // - 0xAA (1010 1010 in binary)
  //
  //   bottom  top    b    t       b    t    b    t
  //        1    0    1    0       1    0    1    0   (same for next 128-bit lane)
  // - 0xa6a5_a5a4_a3a2_a2a1, 0xb4b3_b3b2_b1a8_a8a7,  0xd2d1_d1c8_c7c6_c6c5, 0xd8d7_d7d6_d5d4_d4d3
  // - 0x0a6a_0a5a_0a3a_0a2a, 0x0b4b_0b3b_0b1a_0a8a,  0x0d2d_0d1c_0c7c_0c6c, 0x0d8d_0d7d_0d5d_0d4d
  // to:
  // - 0x0a6a_a5a4_0a3a_a2a1, 0x0b4b_b3b2_0b1a_a8a7, 0x0d2d_d1c8_0c7c_c6c5, 0x0d8d_d7d6_0d5d_d4d3

  f0 = #VPBLEND_16u16(f0, g0, 0xAA);
  f1 = #VPBLEND_16u16(f1, g1, 0xAA);

  // next, mask at 12 bits (0xFFF)
  // from:
  // - 0x0a6a_a5a4_0a3a_a2a1, 0x0b4b_b3b2_0b1a_a8a7, 0x0d2d_d1c8_0c7c_c6c5, 0x0d8d_d7d6_0d5d_d4d3
  // to:
  // - 0x0a6a_05a4_0a3a_02a1, 0x0b4b_03b2_0b1a_08a7, 0x0d2d_01c8_0c7c_06c5, 0x0d8d_07d6_0d5d_04d3

  f0 = #VPAND_256(f0, mask);
  f1 = #VPAND_256(f1, mask);

  // KYBER_Q is 3329 or 0xd01
  //
  // bounds:
  // - 0x0d01_0d01_0d01_0d01, ...
  //
  // some input:
  // - 0x0a6a_05a4_0a3a_02a1, 0x0b4b_03b2_0b1a_08a7, 0x0d2d_01c8_0c7c_06c5, 0x0d8d_07d6_0d5d_04d3
  //
  // output (the 'good' results are highlighted with Fs; what about when equal to 3329?)
  // - 0xffff_ffff_ffff_ffff, 0xffff_ffff_ffff_ffff, 0x0000_ffff_ffff_ffff, 0x0000_ffff_0000_ffff
  //
  // intuitively, for i=0 to 15: if bounds[i] > input[i] then 0xffff else 0x0
  g0 = #VPCMPGT_16u16(bounds, f0);
  g1 = #VPCMPGT_16u16(bounds, f1);

  // from Intel intrinsics: "Convert packed signed 16-bit integers from a and b to packed 8-bit integers using signed saturation"
  // intuitively, each u16 ffff -> ff and 0000 -> 00
  // g0 = g0[0..7] || g1[0..7] || g0[8..15] || g1[8..15], where each u16 "goes to" u8
  g0 = #VPACKSS_16u16(g0, g1);

  // from Intel intrinsics: "Create mask from the most significant bit of each 8-bit element in a, and store the result in dst."
  #declassify
  good = #VPMOVMSKB_u256u64(g0);

  good = #protect(good, ms);

  // at this point, the bit count of good contains the number of 'good' elements

  // g0
  t0_0 = good;
  t0_0 &= 0xFF; // g0[0..7]

  shuffle_0 = (256u) #VMOV(sst[u64 t0_0]);
  ?{}, t0_0 = #POPCNT_64(t0_0);
  t0_0 += counter;

  t0_1 = good;
  t0_1 >>= 16;
  t0_1 &= 0xFF; // g0[8..15]
  shuffle_0_1 = #VMOV(sst[u64 t0_1]);
  ?{}, t0_1 = #POPCNT_64(t0_1);
  t0_1 += t0_0;

  // g1
  t1_0 = good;
  t1_0 >>= 8;
  t1_0 &= 0xFF; // g1[0..7]
  shuffle_1 = (256u) #VMOV(sst[u64 t1_0]);
  ?{}, t1_0 = #POPCNT_64(t1_0);
  t1_0 += t0_1;

  t1_1 = good;
  t1_1 >>= 24;
  t1_1 &= 0xFF; // g1[8..15]
  shuffle_1_1 = #VMOV(sst[u64 t1_1]);
  ?{}, t1_1 = #POPCNT_64(t1_1);
  t1_1 += t1_0;

  //

  shuffle_0 = #VINSERTI128(shuffle_0, shuffle_0_1, 1);
  shuffle_1 = #VINSERTI128(shuffle_1, shuffle_1_1, 1);

  //

  shuffle_t = #VPADD_32u8(shuffle_0, ones);
  shuffle_0 = #VPUNPCKL_32u8(shuffle_0, shuffle_t);

  shuffle_t = #VPADD_32u8(shuffle_1, ones);
  shuffle_1 = #VPUNPCKL_32u8(shuffle_1, shuffle_t);

  f0 = #VPSHUFB_256(f0, shuffle_0);
  f1 = #VPSHUFB_256(f1, shuffle_1);

  //

  pol.[u128 2*counter] = (128u)f0;
  pol.[u128 2*t0_0] = #VEXTRACTI128(f0, 1);
  pol.[u128 2*t0_1] = (128u)f1;
  pol.[u128 2*t1_0] = #VEXTRACTI128(f1, 1);

  counter = t1_1;

  return pol, counter;
}

// safe-write (ensured to write inside the array...)
inline fn __write_u128_boundchk
( reg mut ptr u16[MLKEM_N] pol
, reg u64 ctr
, reg u128 data
, #msf reg u64 ms
) -> reg ptr u16[MLKEM_N], #msf reg u64
ensures { \all (k \in 0:((2*MLKEM_N))) (is_arr_init(result.0,k,1) == (is_arr_init(pol,k,1) || (2* (int)ctr <= k && k< 2*(int) ctr + max(0,min(16,2 * (MLKEM_N - (int) ctr)))))) }
{
  reg u64 data_u64;
  reg bool condition_8 condition_4 condition_2 condition_1;

  condition_8 = (ctr <= MLKEM_N-8);
  if ( condition_8 ) {
    ms = #update_msf(condition_8, ms);

    pol.[u128 2*(int)ctr] = data;
    ctr += 8;
  } else
  {
    ms = #update_msf(!condition_8, ms);

    data_u64 = #MOVV(data);

    condition_4 = (ctr <= MLKEM_N-4);
    if ( condition_4 ) {
      ms = #update_msf(condition_4, ms);

      pol.[u64 2*(int)ctr] = data_u64;
      data_u64 = #VPEXTR_64(data, 1);
      ctr += 4;
    } else
    { ms = #update_msf(!condition_4, ms); }

    condition_2 = (ctr <= MLKEM_N-2);
    if ( condition_2 ) {
      ms = #update_msf(condition_2, ms);

      pol.[u32 2*(int)ctr] = (32u) data_u64;
      data_u64 >>= 32;
      ctr += 2;
    } else
    { ms = #update_msf(!condition_2, ms); }

    condition_1 = (ctr <= MLKEM_N-1);
    if ( condition_1 ) {
      ms = #update_msf(condition_1, ms);

      pol.[u16 2*(int)ctr] = (16u) data_u64;
      //ctr += 1;
    } else
    { ms = #update_msf(!condition_1, ms); }
  }

  return pol, ms;
}

inline fn __gen_matrix_buf_rejection_filter24
( reg mut ptr u16[MLKEM_N] pol
, reg u64 counter
, reg const ptr u8[BUF_size] buf
, reg u64 buf_offset // in bytes

, reg u256 load_shuffle mask bounds
, reg ptr u8[2048] sst
, reg u256 ones
, #msf reg u64 ms
) -> reg ptr u16[MLKEM_N], reg u64, #msf reg u64
requires {is_arr_init(buf,0,BUF_size) && is_arr_init(sst,0,2048) &&
          0<= (int) counter &&  // (int) counter + 32 <= MLKEM_N &&
          0 <= (int) buf_offset && (int) buf_offset + 32 <= BUF_size}
ensures { \all (k \in 0:(2*MLKEM_N)) (is_arr_init(result.0,k,1) == (is_arr_init(pol,k,1) || (2 * (int) counter <= k && k< 2 * (int) result.1))) }
ensures {(int) counter <=result.1 && (int) result.1 <= MLKEM_N}
{
  reg u256 f0 g0 g1;
  reg u256 shuffle_0 shuffle_t;
  reg u128 shuffle_0_1 t128;
  reg u64 good t0_0 t0_1;

  f0 = #VPERMQ(buf.[u256 (int) buf_offset + 0 ], (4u2)[2,1,1,0]);
  f0 = #VPSHUFB_256(f0, load_shuffle);
  g0 = #VPSRL_16u16(f0, 4);
  f0 = #VPBLEND_16u16(f0, g0, 0xAA);
  f0 = #VPAND_256(f0, mask);
  g0 = #VPCMPGT_16u16(bounds, f0);
  g1 = #set0_256();
  g0 = #VPACKSS_16u16(g0, g1);
  #declassify
  good = #VPMOVMSKB_u256u64(g0);

  good = #protect(good, ms);

  // g0
  t0_0 = good;
  t0_0 &= 0xFF; // g0[0..7]
  shuffle_0 = (256u) #VMOV(sst[u64 t0_0]);
  ?{}, t0_0 = #POPCNT_64(t0_0);
  t0_0 += counter;

  t0_1 = good;
  t0_1 >>= 16;
  t0_1 &= 0xFF; // g0[8..15]
  shuffle_0_1 = #VMOV(sst[u64 t0_1]);
  ?{}, t0_1 = #POPCNT_64(t0_1);
  t0_1 += t0_0;

  //
  shuffle_0 = #VINSERTI128(shuffle_0, shuffle_0_1, 1);
  shuffle_t = #VPADD_32u8(shuffle_0, ones);
  shuffle_0 = #VPUNPCKL_32u8(shuffle_0, shuffle_t);
  f0 = #VPSHUFB_256(f0, shuffle_0);
  //

  t128 = (128u) f0;
  pol, ms = __write_u128_boundchk(pol, counter, t128, ms);

  t128 = #VEXTRACTI128(f0, 1);
  pol, ms = __write_u128_boundchk(pol, t0_0, t128, ms);

  counter = t0_1;

  return pol, counter, ms;
}


fn _gen_matrix_buf_rejection
( reg mut ptr u16[MLKEM_N] pol		// polynomial
, reg u64 counter			// number of coefs. already sampled
, reg const ptr u8[BUF_size] buf	// whole buffer (size=21+21+25 (+1 pad))
, reg u64 buf_offset			// start looking at... (bytes)

) -> reg ptr u16[MLKEM_N], reg u64	// pol. and counter
requires {is_arr_init(buf,0,BUF_size) && 0<= (int) counter &&  (int) counter <= MLKEM_N &&
          0 <= (int) buf_offset && (int) buf_offset < BUF_size}
ensures { \all (k \in 0:(2*MLKEM_N)) (is_arr_init(result.0,k,1) == (is_arr_init(pol,k,1) || (2* (int) counter <= k && k< 2* (int) result.1))) }
ensures {(int)counter<=result.1 && (int) result.1 <= MLKEM_N}
{
  reg bool condition_loop;
  reg ptr u8[2048] sst;
  reg u256 load_shuffle mask bounds ones;
  #msf reg u64 ms;
  stack u64 saved_buf_offset;

  ms = #init_msf();

  load_shuffle = sample_load_shuffle[u256 0];
  mask = sample_mask;
  bounds = sample_q;
  ones = sample_ones;
  sst = sample_shuffle_table;

  saved_buf_offset = buf_offset;
  buf_offset = buf_offset;

  while
    { condition_loop = buf_offset <u 3 * 168 - 48 + 1;
    }
  ( condition_loop )
    {
    ms = #update_msf(condition_loop, ms);
    condition_loop = counter <u MLKEM_N - 32 + 1;
    if condition_loop {
      ms = #update_msf(condition_loop, ms);
      pol, counter = __gen_matrix_buf_rejection_filter48(pol, counter, buf, buf_offset, load_shuffle, mask, bounds, sst, ones, ms);
      saved_buf_offset += 48;
      buf_offset = saved_buf_offset;
      buf_offset = #protect(buf_offset, ms);
    } else {
      ms = #update_msf(!condition_loop, ms);
      buf_offset = 3 * 168;
    }
    }
  ms = #update_msf(!condition_loop, ms);

  buf_offset = saved_buf_offset;
  buf_offset = #protect(buf_offset, ms);

  while { condition_loop = buf_offset <u 3 * 168 - 24 + 1; }
        ( condition_loop )
  {
    ms = #update_msf(condition_loop, ms);
    condition_loop = counter <u MLKEM_N;
    if condition_loop {
      ms = #update_msf(condition_loop, ms);
() = #spill(buf_offset);
      pol, counter, ms = __gen_matrix_buf_rejection_filter24(pol, counter, buf, buf_offset, load_shuffle, mask, bounds, sst, ones, ms);
() = #unspill(buf_offset);
      buf_offset = #protect(buf_offset, ms);
      buf_offset += 24;
    } else {
      ms = #update_msf(!condition_loop, ms);
      buf_offset = 3 * 168;
    }
  }

  return pol, counter;
}

param int IDX_TABLE_SIZE = 32 * (MLKEM_K-2);

inline fn gen_matrix_get_indexes(
  reg u64 b,
  reg u64 _t)
  ->
  reg u64
requires {0 <= b + (_t << (MLKEM_K + 1)) && b + ( _t << (MLKEM_K + 1)) <= 32 * (MLKEM_K-2) - 8}
{
  reg u64 t;
  reg ptr u8[IDX_TABLE_SIZE] idxs;
  idxs = gen_matrix_indexes;

  t = _t; t <<= (MLKEM_K + 1); // transposed table in the second half
  b += t;

  t = idxs.[u64 b];

  return t;
}

fn __gen_matrix_fill_polynomial
( reg mut ptr u16[MLKEM_N] pol
, reg mut ptr u8[BUF_size] buf
) -> reg ptr u16[MLKEM_N], reg ptr u8[BUF_size]
requires {is_arr_init(buf, 0, BUF_size)}
ensures { is_arr_init(result.0,0,MLKEM_N * 2) && is_arr_init(result.1,0,BUF_size)}
{
  reg u64 counter, buf_offset;

  buf_offset = 0;
  counter = 0;
  pol, counter = _gen_matrix_buf_rejection(pol, counter, buf, buf_offset);
  buf_offset = 2*168;
  while (counter < MLKEM_N) {
    buf = _shake128_next_state(buf);
    pol, counter = _gen_matrix_buf_rejection(pol, counter, buf, buf_offset);
  }

  return pol, buf;
}

fn _gen_matrix_sample_four_polynomials
( reg mut ptr u16[4*MLKEM_N] polx4
, reg mut ptr u8[BUF_size * 4] buf
, reg ptr u8[32] rho
, reg u64 pos_entry
, reg u64 transposed
) -> reg ptr u16[4*MLKEM_N], reg ptr u8[BUF_size * 4]
requires {is_arr_init(rho,0,32) && 0 <= pos_entry + (transposed << (MLKEM_K + 1)) &&
          pos_entry + (transposed << (MLKEM_K + 1)) <= 32 * (MLKEM_K-2) - 8}
ensures { is_arr_init(result.0,0,2048)}
{
  reg ptr u16[MLKEM_N] pol;
  stack u256[25] state;
  reg ptr u256[25] stx4;
  stack u8[8] indexes;

  indexes.[u64 0] = gen_matrix_get_indexes(pos_entry, transposed);

  stx4 = state;
  stx4 = _shake128x4_absorb_A32_A2(stx4, rho, indexes);
  _, buf = _shake128x4_squeeze3blocks(stx4, buf);

  pol = polx4[0*MLKEM_N:MLKEM_N];
  pol, buf[BUF_size * 0 : BUF_size] = __gen_matrix_fill_polynomial(pol, buf[BUF_size * 0 : BUF_size]);
  polx4[0*MLKEM_N:MLKEM_N] = pol;

  pol = polx4[1*MLKEM_N:MLKEM_N];
  pol, buf[BUF_size * 1 : BUF_size] = __gen_matrix_fill_polynomial(pol, buf[BUF_size * 1 : BUF_size]);
  polx4[1*MLKEM_N:MLKEM_N] = pol;

  pol = polx4[2*MLKEM_N:MLKEM_N];
  pol, buf[BUF_size * 2 : BUF_size] = __gen_matrix_fill_polynomial(pol, buf[BUF_size * 2 : BUF_size]);
  polx4[2*MLKEM_N:MLKEM_N] = pol;

  pol = polx4[3*MLKEM_N:MLKEM_N];
  pol, buf[BUF_size * 3 : BUF_size] = __gen_matrix_fill_polynomial(pol, buf[BUF_size * 3 : BUF_size]);
  polx4[3*MLKEM_N:MLKEM_N] = pol;

  return polx4, buf;
}

inline fn __gen_matrix_sample_one_polynomial
( reg mut ptr u16[MLKEM_N] pol
, reg mut ptr u8[BUF_size] buf
, reg ptr u8[32] rho
, reg u16 rc
) -> reg ptr u16[MLKEM_N], reg ptr u8[BUF_size]
requires {is_arr_init(rho,0,32)}
ensures { is_arr_init(result.0,0,0) && is_arr_init(result.1,0,BUF_size)}
{
  reg u256[7] stavx2;
  stack u8[2] pos;

  pos[u16 0] = rc;
  stavx2 = _shake128_absorb_A32_A2(rho, pos);
  buf = _shake128_squeeze3blocks(buf, stavx2);

  pol, buf = __gen_matrix_fill_polynomial(pol, buf);

  return pol, buf;
}
